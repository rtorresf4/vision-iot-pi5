# Vision + IoT on Raspberry Pi 5 (Educational Portfolio)

> **Goal:** Build an **edge AI system** on a Raspberry Pi 5 (8GB) that detects defects in industrial parts in real time, integrates IoT sensors, and streams results to an interactive dashboard.  
>
> This repository is designed both as a **technical prototype** and as an **educational portfolio**, showing not only the *code* but also the *thought process* behind each design choice.

---

## ğŸ¯ Project Objectives
- Implement a **lightweight object detection model** (YOLOv8n exported to ONNX/TFLite).  
- Integrate **IoT sensors** (temperature, motion) via MQTT.  
- Develop a **Streamlit dashboard** for live video, KPIs, and alerts.  
- Train a **custom dataset** (OK vs Defective parts).  
- Deliver a **robust industrial-ready prototype** documented for recruiters and engineers.  

---

## ğŸ—ï¸ System Architecture
```
[USB Camera] â†’ [Raspberry Pi 5: OpenCV + YOLOv8n (ONNX/TFLite)]
    â”œâ”€ Detection results â†’ MQTT â†’ [Streamlit Dashboard]
    â””â”€ Telemetry (CPU temp, FPS, health)

[Sensors: DHT22, PIR] â†’ MQTT â†’ Dashboard
```

**MQTT Topics:**
- `factory/line1/detections` â†’ detection results (JSON per frame).  
- `factory/line1/telemetry` â†’ system telemetry (CPU, memory, temp).  
- `factory/line1/sensors` â†’ IoT data (temperature, humidity, motion).  
- `factory/line1/status` â†’ LWT for online/offline.  

---

## ğŸ› ï¸ Tech Stack
- **Hardware:** Raspberry Pi 5 (8GB), USB webcam, DHT22 sensor, PIR sensor.  
- **Software:** Python, OpenCV, ONNX Runtime / TFLite, MQTT (Mosquitto), Streamlit.  
- **ML Training:** Ultralytics YOLOv8, Google Colab / local GPU.  
- **Deployment:** systemd services (with hardening), Makefile, pre-commit hooks.  
- **CI/CD:** GitHub Actions (lint, type-check, tests).  
- **IDE:** Visual Studio Code (official `.deb` installation, not Snap).  

---

## ğŸš€ Quick Start

### Setup on Ubuntu VM / Development Machine
```bash
sudo apt update && sudo apt install -y git python3 python3-venv python3-pip ffmpeg
git clone https://github.com/<YOUR_USERNAME>/vision-iot-pi5.git
cd vision-iot-pi5
python3 -m venv .venv
source .venv/bin/activate
python -m pip install --upgrade pip wheel
pip install -r requirements.txt
pip install -r requirements-dev.txt
```

### Setup on Raspberry Pi 5
```bash
sudo apt update && sudo apt install -y git python3 python3-venv python3-pip cmake ffmpeg mosquitto mosquitto-clients
git clone https://github.com/<YOUR_USERNAME>/vision-iot-pi5.git
cd vision-iot-pi5
python3 -m venv ~/vision
source ~/vision/bin/activate
python -m pip install --upgrade pip wheel
pip install -r requirements.txt
```

### Run detector
```bash
make run-detector
```

### Run dashboard
```bash
make run-dashboard
```

### Capture dataset
```bash
python apps/tools/capture_dataset.py --label ok
python apps/tools/capture_dataset.py --label defect --every 5
```

---

## ğŸ§ª CÃ³mo probar en tu PC (sin Raspberry Pi)

### 1) Preparar entorno
- Crear entorno e instalar deps:
  ```bash
  python3 -m venv .venv
  source .venv/bin/activate
  make setup
  make dev   # opcional (linter/formatter/hooks)
  ```

### 2) Comprobar la cÃ¡mara
- Probar detecciÃ³n de dispositivos y resoluciones comunes (recomendado MJPG):
  ```bash
  make check-camera
  ```
- Si todo bien, capturar un pequeÃ±o lote con previsualizaciÃ³n:
  ```bash
  make capture-ok
  make capture-defect
  ```
- Resultado:
  - ImÃ¡genes en `data/ok/` y `data/defect/`
  - Metadatos en `data/metadata.csv`

Consejos:
- Si `video0` falla, prueba `--device 1` en `apps/tools/check_camera.py`.
- 720p (1280x720) suele ir mÃ¡s fluido que 1080p en CPU.
- Cierra apps que usen la webcam (Zoom/Teams/Chrome) si no abre.

### 3) Probar el dashboard + MQTT local
1. Instala un broker local (Ubuntu/Debian):
   ```bash
   sudo apt update && sudo apt install -y mosquitto mosquitto-clients
   sudo systemctl enable --now mosquitto
   ```
2. Arranca el dashboard:
   ```bash
   make run-dashboard
   ```
3. Simula detecciones (publicaciÃ³n cada 1s):
   ```bash
   make sim-detections
   ```
4. VerÃ¡s las mÃ©tricas en el dashboard. Para parar el simulador: Ctrl+C.

### 4) (Opcional) Probar el detector en PC
- Coloca un modelo ONNX en `models/yolov8n.onnx` (o ajusta la ruta en `apps/pi_detector/config.yaml`).
- Conecta tu webcam y ejecuta:
  ```bash
  make run-detector
  ```
- El detector publicarÃ¡ resultados a MQTT en `factory/line1/detections`.

### 5) Calidad de cÃ³digo
```bash
make lint
make test
```

### Troubleshooting rÃ¡pido
- CÃ¡mara no abre: revisa `make check-camera`, FOURCC `--fourcc MJPG` y permisos; prueba otro puerto USB.
- Dashboard no muestra datos: confirma que Mosquitto estÃ¡ activo (`sudo systemctl status mosquitto`) y que `make sim-detections` no lanza errores de conexiÃ³n.
- Alto uso de CPU: reduce resoluciÃ³n a 640Ã—480 en las herramientas y en la configuraciÃ³n.

---

## ğŸ–¥ï¸ Recommended IDE â€” Visual Studio Code

It is recommended to install **Visual Studio Code from the official `.deb` package**, not the Snap Store, for better performance and compatibility.

### Install VS Code (.deb)
```bash
wget -O code.deb https://update.code.visualstudio.com/latest/linux-deb-x64/stable
sudo apt install ./code.deb
```

After installation, run with:
```bash
code
```

### Suggested Extensions
- **Python** (ms-python.python)  
- **Pylance** (ms-python.vscode-pylance)  
- **Jupyter** (ms-toolsai.jupyter)  
- **Remote - SSH** (ms-vscode-remote.remote-ssh)  
- **Prettier - Code Formatter** (esbenp.prettier-vscode)  
- **GitLens** (eamodio.gitlens)  
- **Docker** (ms-azuretools.vscode-docker) (optional for future)  

> Pro tip: mention in your portfolio that you used **Ubuntu 22.04 + VS Code (with Python, Pylance, Remote SSH)** â†’ it shows a professional development workflow.  

---

## ğŸ“¦ Repository Structure
```
apps/
  pi_detector/         # Inference pipeline (ONNX/TFLite) + MQTT publisher
  streamlit_dashboard/ # Live KPIs and video
  sensors/             # IoT sensor integration
  tools/               # Dataset capture tool
deploy/
  systemd/             # Hardened systemd services
  scripts/             # Install/run scripts
docs/
  INDUSTRIAL_NOTES.md  # Notes for recruiters (industrial-ready)
models/                # YOLO models (.onnx, .tflite)
data/                  # Images, labels, metadata.csv
training/              # Training configs + Colab notebook
tests/                 # Pytest tests
```

---

## ğŸ§ª Continuous Integration
This repo includes a **GitHub Actions workflow** (`.github/workflows/ci.yml`) that:  
- Runs `ruff`, `black`, `mypy` to ensure code quality.  
- Executes unit tests (`pytest`).  
- Builds on **Ubuntu latest** with Python 3.11.  

> âœ… Demonstrates professional workflows (important for industrial/automotive companies).  

---

## ğŸ“Š Metrics to Deliver
- **Detection performance:** mAP50 â‰¥ 0.80 on validation set.  
- **Runtime speed:** â‰¥ 15 FPS @ 640Ã—480 on Raspberry Pi 5.  
- **Latency:** < 150 ms per frame end-to-end.  
- **IoT reliability:** â‰¥ 99% MQTT message delivery, auto-reconnect < 5s.  

---

## ğŸ“ Educational Narrative
Each sprint will be documented with:  
- **What I did** â†’ concrete steps.  
- **Results** â†’ screenshots, metrics, plots.  
- **Lessons learned** â†’ insights, trade-offs, mistakes.  

This transforms the repository into both a **working prototype** and a **teaching resource**.  

---

## ğŸ­ Industrial-Ready Highlights
- Config-driven runtime (`apps/pi_detector/config.yaml`).  
- Robust MQTT client with LWT + exponential backoff.  
- Hardened `systemd` services (`ProtectSystem`, `PrivateTmp`, etc.).  
- Separate requirements for runtime, CI, and training.  
- Capture tool for building **custom datasets**.  

See [`docs/INDUSTRIAL_NOTES.md`](docs/INDUSTRIAL_NOTES.md) for recruiter-focused notes (Siemens, Bosch, BMW, Audi, Mercedes, NVIDIA).  

---

## ğŸ“ˆ Roadmap
- âœ… Industrial-ready baseline (this repo).  
- â³ Dataset capture (ongoing).  
- â³ Model training & export (Colab + YOLOv8).  
- â³ Inference on Pi5 (FPS & latency benchmarking).  
- â³ Dashboard enhancements (streamlit-webrtc, SQLite history).  
- â³ Final demo video + LinkedIn/Medium post.  

---

## ğŸ“œ License
MIT â€” free to use, modify, and share.
